import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import os
import json
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class GradCAMGenerator:
    """
    ğŸ“ Grad-CAM: Shows what the model focuses on in images
    Improved version based on working Colab implementation
    """

    def __init__(self, model, class_names, img_size=(256, 256)):
        self.model = model
        self.class_names = class_names
        self.img_size = img_size
        self.num_classes = len(class_names)
        logger.info(f"âœ… GradCAMGenerator initialized with {self.num_classes} classes")

    def load_and_preprocess_image(self, image_path):
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img = keras.preprocessing.image.load_img(
                image_path,
                target_size=self.img_size
            )

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ array
            img_array = keras.preprocessing.image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)

            # ØªØ·Ø¨ÙŠØ¹ (Ù…Ø¹Ø§ÙŠÙŠØ± EfficientNetV2)
            img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(
                img_array.copy()
            )

            return img_array, img_preprocessed
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {str(e)}")
            return None, None

    def make_gradcam_heatmap(self, img_array, model):
        """
        Grad-CAM Ù…Ø¨Ø³Ø· - ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬
        Based on working Colab implementation âœ…
        """
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(img_array.copy())

            # Ø¥ÙŠØ¬Ø§Ø¯ Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© Conv ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            last_conv_layer = None
            for layer in reversed(model.layers):
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø·Ø¨Ù‚Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø·Ø¨Ù‚Ø§Øª ÙØ±Ø¹ÙŠØ© (base_model)
                if hasattr(layer, 'layers'):
                    for sublayer in reversed(layer.layers):
                        if isinstance(sublayer, keras.layers.Conv2D):
                            last_conv_layer = sublayer
                            break
                    if last_conv_layer:
                        break
                # Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Conv2D Ù…Ø¨Ø§Ø´Ø±Ø©
                elif isinstance(layer, keras.layers.Conv2D):
                    last_conv_layer = layer
                    break

            if last_conv_layer is None:
                logger.warning("No Conv2D layer found! Using fallback method")
                return self._fallback_saliency_map(img_preprocessed), None

            logger.info(f"  âœ“ Using Conv layer: {last_conv_layer.name}")

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø¨Ù‚Ø©
            outputs = []

            # Ù†Ø­ÙØ¸ Ø§Ù„Ù€ output Ø£Ø«Ù†Ø§Ø¡ forward pass
            original_call = last_conv_layer.call

            def new_call(inputs, **kwargs):
                x = original_call(inputs, **kwargs)
                outputs.append(x)
                return x

            last_conv_layer.call = new_call

            # Forward pass Ù…Ø¹ GradientTape
            with tf.GradientTape() as tape:
                # Ù…Ø³Ø­ outputs Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
                outputs.clear()

                # Forward pass
                preds = model(img_preprocessed, training=False)
                pred_index = tf.argmax(preds[0])
                class_channel = preds[:, pred_index]

                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ conv_output Ø§Ù„Ù…Ø­ÙÙˆØ¸
                if len(outputs) > 0:
                    conv_output = outputs[0]
                    tape.watch(conv_output)
                else:
                    # Fallback: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰
                    last_conv_layer.call = original_call
                    grad_model = keras.Model(model.input, [last_conv_layer.output, model.output])

                    with tf.GradientTape() as tape2:
                        conv_output, preds2 = grad_model(img_preprocessed)
                        pred_index = tf.argmax(preds2[0])
                        class_channel = preds2[:, pred_index]

                    grads = tape2.gradient(class_channel, conv_output)
                    last_conv_layer.call = original_call

                    if grads is None:
                        logger.warning("Gradients are None, using fallback")
                        return self._fallback_saliency_map(img_preprocessed), preds[0].numpy()

                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
                    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

                    # Ø¥Ù†Ø´Ø§Ø¡ heatmap
                    conv_output = conv_output[0]
                    heatmap = conv_output @ pooled_grads[..., tf.newaxis]
                    heatmap = tf.squeeze(heatmap)

                    # ØªØ·Ø¨ÙŠØ¹
                    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)

                    return heatmap.numpy(), preds2[0].numpy()

            # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            last_conv_layer.call = original_call

            # Ø­Ø³Ø§Ø¨ gradients
            grads = tape.gradient(class_channel, conv_output)

            if grads is None:
                logger.warning("Gradients are None after first attempt, trying alternative method")
                # Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„
                grad_model = keras.Model(model.input, [conv_output, model.output])

                with tf.GradientTape() as tape:
                    conv_output, preds = grad_model(img_preprocessed)
                    pred_index = tf.argmax(preds[0])
                    class_channel = preds[:, pred_index]

                grads = tape.gradient(class_channel, conv_output)

                if grads is None:
                    logger.warning("Still None, using fallback")
                    return self._fallback_saliency_map(img_preprocessed), preds[0].numpy()

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

            # Ø¥Ù†Ø´Ø§Ø¡ heatmap
            conv_output = conv_output[0]
            heatmap = conv_output @ pooled_grads[..., tf.newaxis]
            heatmap = tf.squeeze(heatmap)

            # ØªØ·Ø¨ÙŠØ¹
            heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)

            logger.info("âœ… Grad-CAM computed successfully")
            return heatmap.numpy(), preds[0].numpy()

        except Exception as e:
            logger.error(f"Error in Grad-CAM: {str(e)}")
            import traceback
            traceback.print_exc()
            # Ø§Ø³ØªØ®Ø¯Ù… fallback
            try:
                img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(img_array.copy())
                preds = model.predict(img_preprocessed, verbose=0)
                return self._fallback_saliency_map(img_preprocessed), preds[0]
            except:
                return np.zeros((self.img_size[0], self.img_size[1])), None

    def _fallback_saliency_map(self, img_preprocessed):
        """
        Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©: Saliency map Ø¨Ø³ÙŠØ·Ø©
        """
        try:
            with tf.GradientTape() as tape:
                img_tensor = tf.cast(img_preprocessed, tf.float32)
                tape.watch(img_tensor)
                predictions = self.model(img_tensor, training=False)
                pred_class_idx = tf.argmax(predictions[0])
                class_channel = predictions[:, pred_class_idx]

            grads = tape.gradient(class_channel, img_tensor)

            if grads is None:
                logger.warning("Gradients are None in fallback")
                return np.zeros((self.img_size[0], self.img_size[1]))

            # Enhanced processing
            grads_abs = tf.abs(grads)
            saliency = tf.reduce_mean(grads_abs, axis=-1)
            saliency = saliency[0]

            # ØªØ·Ø¨ÙŠØ¹
            saliency_np = saliency.numpy()
            saliency_np = (saliency_np - saliency_np.min()) / (saliency_np.max() - saliency_np.min() + 1e-10)

            logger.info("âœ… Fallback saliency map computed")
            return saliency_np

        except Exception as e:
            logger.error(f"Error in fallback saliency map: {str(e)}")
            return np.zeros((self.img_size[0], self.img_size[1]))

    def process_image(self, image_path):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ù…Ù„Ø© Ù„ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© - Improved version âœ…
        """
        try:
            logger.info(f"ğŸ“¸ Processing: {os.path.basename(image_path)}")

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img_array, img_preprocessed = self.load_and_preprocess_image(image_path)

            if img_array is None:
                return None

            # Ø­Ø³Ø§Ø¨ Grad-CAM (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)
            heatmap, preds = self.make_gradcam_heatmap(img_array, self.model)

            # Ø¥Ø°Ø§ Ù…Ø§ Ø­ØµÙ„Ù†Ø§ Ø¹Ù„Ù‰ predictions Ù…Ù† Grad-CAMØŒ Ø§Ø­ØµÙ„ Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ù†ÙØµÙ„Ø©
            if preds is None:
                preds = self.model.predict(img_preprocessed, verbose=0)[0]

            pred_class_idx = np.argmax(preds)
            confidence = preds[pred_class_idx]

            # Get top 3 predictions
            top3_indices = np.argsort(preds)[-3:][::-1]
            top3_predictions = [
                {
                    'class_name': self.class_names[idx],
                    'confidence': float(preds[idx]),
                    'index': int(idx)
                }
                for idx in top3_indices
            ]

            logger.info(f"  ğŸ¯ Prediction: {self.class_names[pred_class_idx]} ({confidence:.1%})")

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_img = keras.preprocessing.image.load_img(image_path)
            original_array = keras.preprocessing.image.img_to_array(original_img) / 255.0

            # ØªÙƒØ¨ÙŠØ± heatmap Ù„Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            heatmap_resized = cv2.resize(
                heatmap,
                (original_array.shape[1], original_array.shape[0])
            )

            # ØªÙ„ÙˆÙŠÙ† heatmap (Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© Colab - COLORMAP_JET)
            heatmap_colored = cv2.applyColorMap(
                np.uint8(255 * heatmap_resized),
                cv2.COLORMAP_JET
            )
            heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)  # ØªØ­ÙˆÙŠÙ„ Ù…Ù† BGR Ø¥Ù„Ù‰ RGB
            heatmap_colored = heatmap_colored / 255.0

            # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± (Ù†ÙØ³ Ù†Ø³Ø¨Ø© Colab: 50% original + 50% heatmap)
            overlay = original_array * 0.5 + heatmap_colored * 0.5

            return {
                'original': original_array,
                'heatmap': heatmap_resized,
                'heatmap_colored': heatmap_colored,
                'overlay': overlay,
                'predictions': preds,
                'pred_class_idx': int(pred_class_idx),
                'confidence': float(confidence),
                'class_name': self.class_names[pred_class_idx],
                'top3_predictions': top3_predictions,
                'image_name': os.path.basename(image_path)
            }

        except Exception as e:
            logger.error(f"Error processing image {image_path}: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def convert_to_base64(self, img_array):
        """
        ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© numpy Ø¥Ù„Ù‰ base64 Ù„Ù„Ù€ JSON
        """
        try:
            import base64
            from io import BytesIO
            from PIL import Image

            # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù‚ÙŠÙ… Ø¨ÙŠÙ† 0-255
            if img_array.max() <= 1.0:
                img_uint8 = np.uint8(img_array * 255)
            else:
                img_uint8 = np.uint8(img_array)

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© PIL
            pil_img = Image.fromarray(img_uint8)

            # Ø­ÙØ¸ ÙÙŠ BytesIO
            buffer = BytesIO()
            pil_img.save(buffer, format='PNG', quality=95)  # PNG Ø¨Ø¯Ù„ JPEG Ù„Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ø¹Ù„Ù‰

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
            img_base64 = base64.b64encode(buffer.getvalue()).decode()

            return f"data:image/png;base64,{img_base64}"

        except Exception as e:
            logger.error(f"Error converting to base64: {str(e)}")
            return None

    def generate_gradcam_samples(self, image_paths, output_dir):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ± ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ - Enhanced version âœ…
        """
        try:
            logger.info(f"ğŸ”® Starting Grad-CAM generation for {len(image_paths)} images...")
            results = []

            for idx, img_path in enumerate(image_paths):
                logger.info(f"Processing {idx + 1}/{len(image_paths)}: {os.path.basename(img_path)}")

                result = self.process_image(img_path)

                if result is None:
                    logger.warning(f"Failed to process {img_path}")
                    continue

                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ base64
                result['original_base64'] = self.convert_to_base64(result['original'])
                result['heatmap_base64'] = self.convert_to_base64(result['heatmap_colored'])
                result['overlay_base64'] = self.convert_to_base64(result['overlay'])

                # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (arrays) Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                del result['original']
                del result['heatmap']
                del result['heatmap_colored']
                del result['overlay']

                # ØªØ­ÙˆÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result['all_predictions'] = {
                    self.class_names[i]: float(result['predictions'][i])
                    for i in range(len(self.class_names))
                }
                del result['predictions']

                results.append(result)
                logger.info(f"  âœ… Completed {idx + 1}/{len(image_paths)}")

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            os.makedirs(output_dir, exist_ok=True)

            output_data = {
                'generated_at': datetime.now().isoformat(),
                'num_samples': len(results),
                'class_names': self.class_names,
                'img_size': list(self.img_size),
                'samples': results
            }

            json_path = os.path.join(output_dir, 'gradcam_data.json')
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)

            logger.info(f"ğŸ‰ Successfully saved {len(results)} samples to {json_path}")

            return output_data

        except Exception as e:
            logger.error(f"Error generating Grad-CAM samples: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
