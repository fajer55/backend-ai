import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import os
import json
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class GradCAMGenerator:
    """
    ğŸ“ Grad-CAM: Shows what the model focuses on in images
    """
    
    def __init__(self, model, class_names, img_size=(256, 256)):
        self.model = model
        self.class_names = class_names
        self.img_size = img_size
        self.num_classes = len(class_names)
    
    def load_and_preprocess_image(self, image_path):
        """
        ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img = keras.preprocessing.image.load_img(
                image_path, 
                target_size=self.img_size
            )
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ array
            img_array = keras.preprocessing.image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)
            
            # ØªØ·Ø¨ÙŠØ¹ (Ù…Ø¹Ø§ÙŠÙŠØ± EfficientNetV2)
            img_preprocessed = tf.keras.applications.efficientnet_v2.preprocess_input(
                img_array.copy()
            )
            
            return img_array, img_preprocessed
        except Exception as e:
            logger.error(f"Error loading image {image_path}: {str(e)}")
            return None, None
    
    def make_gradcam_heatmap(self, img_preprocessed, pred_class_idx):
        """
        Ø­Ø³Ø§Ø¨ Grad-CAM heatmap - Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ø¹Ù…Ù„ Ù…Ø¹ EfficientNet
        """
        try:
            # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ EfficientNet (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹)
            efficientnet_model = None
            last_conv_layer_name = None

            # 1. Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ EfficientNet
            for layer in self.model.layers:
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø¨Ù‚Ø© Ù‡ÙŠ Ù†Ù…ÙˆØ°Ø¬ EfficientNet
                if hasattr(layer, 'name') and 'efficientnet' in layer.name.lower():
                    efficientnet_model = layer
                    logger.info(f"Found EfficientNet base model: {layer.name}")
                    break
                # Ø£Ùˆ ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙ‡Ø§ Ø·Ø¨Ù‚Ø§Øª ÙØ±Ø¹ÙŠØ© ÙˆØ¥Ø­Ø¯Ø§Ù‡Ø§ Ø§Ø³Ù…Ù‡Ø§ top_conv
                if hasattr(layer, 'layers'):
                    try:
                        # Ø­Ø§ÙˆÙ„ Ø¥ÙŠØ¬Ø§Ø¯ top_conv ÙÙŠ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
                        for sublayer in layer.layers:
                            if sublayer.name == 'top_conv':
                                efficientnet_model = layer
                                logger.info(f"Found model containing top_conv: {layer.name}")
                                break
                    except:
                        pass
                if efficientnet_model:
                    break

            # 2. Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠØŒ Ø§Ø¨Ø­Ø« Ø¹Ù† Ø·Ø¨Ù‚Ø© Conv ÙÙŠÙ‡
            if efficientnet_model:
                known_layers = ['top_conv', 'block7a_project_conv', 'block6a_expand_conv']
                for layer_name in known_layers:
                    try:
                        # Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ
                        test_layer = None
                        for sublayer in efficientnet_model.layers:
                            if sublayer.name == layer_name:
                                test_layer = sublayer
                                break

                        if test_layer:
                            last_conv_layer_name = layer_name
                            logger.info(f"Found conv layer in base model: {layer_name}")
                            break
                    except:
                        continue

            # 3. Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ØŒ Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            if last_conv_layer_name is None:
                logger.info("Searching for conv layers in main model...")
                for layer in reversed(self.model.layers):
                    if isinstance(layer, keras.layers.Conv2D):
                        last_conv_layer_name = layer.name
                        logger.info(f"Found direct conv layer: {layer.name}")
                        break

            if last_conv_layer_name is None:
                logger.warning("No Conv layer found, using fallback saliency map")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            logger.info(f"Using layer for Grad-CAM: {last_conv_layer_name}")

            # 4. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Grad-CAM - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            try:
                if efficientnet_model and last_conv_layer_name:
                    # Ø¥Ù†Ø´Ø§Ø¡ grad_model Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ
                    # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø¨Ù‚Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ±Ø¹ÙŠ
                    conv_layer = None
                    for sublayer in efficientnet_model.layers:
                        if sublayer.name == last_conv_layer_name:
                            conv_layer = sublayer
                            break

                    if conv_layer is None:
                        raise Exception(f"Could not find {last_conv_layer_name} in base model")

                    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… output Ø§Ù„Ø·Ø¨Ù‚Ø©
                    grad_model = keras.Model(
                        inputs=self.model.input,
                        outputs=[conv_layer.output, self.model.output]
                    )
                else:
                    # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                    grad_model = keras.Model(
                        inputs=self.model.input,
                        outputs=[
                            self.model.get_layer(last_conv_layer_name).output,
                            self.model.output
                        ]
                    )
            except Exception as e:
                logger.warning(f"Could not create grad_model: {str(e)}")
                logger.info("Falling back to saliency map method")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # Ø­Ø³Ø§Ø¨ gradients Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GradientTape
            with tf.GradientTape() as tape:
                # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ outputs
                conv_outputs, predictions = grad_model(img_preprocessed, training=False)
                # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                class_channel = predictions[:, pred_class_idx]

            # Ø§Ø­Ø³Ø¨ gradients
            grads = tape.gradient(class_channel, conv_outputs)

            if grads is None:
                logger.warning("Gradients are None, using fallback method")
                return self._simple_saliency_map(img_preprocessed, pred_class_idx)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙˆØ²Ø§Ù† (Global Average Pooling Ø¹Ù„Ù‰ Ø§Ù„Ù€ gradients)
            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

            # Ø¥Ù†Ø´Ø§Ø¡ heatmap
            conv_output = conv_outputs[0]
            heatmap = conv_output @ pooled_grads[..., tf.newaxis]
            heatmap = tf.squeeze(heatmap)

            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù€ heatmap
            heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)

            return heatmap.numpy()

        except Exception as e:
            logger.error(f"Error in make_gradcam_heatmap: {str(e)}")
            logger.info("Using fallback saliency map method")
            return self._simple_saliency_map(img_preprocessed, pred_class_idx)
    
    def _simple_saliency_map(self, img_preprocessed, pred_class_idx):
        """
        Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©: Saliency map Ø¨Ø³ÙŠØ·Ø©
        """
        try:
            with tf.GradientTape() as tape:
                img_tensor = tf.cast(img_preprocessed, tf.float32)
                tape.watch(img_tensor)
                predictions = self.model(img_tensor, training=False)
                class_channel = predictions[:, pred_class_idx]
            
            grads = tape.gradient(class_channel, img_tensor)
            saliency = tf.reduce_max(tf.abs(grads), axis=-1)
            saliency = saliency[0]
            saliency = (saliency - tf.reduce_min(saliency)) / (tf.reduce_max(saliency) - tf.reduce_min(saliency) + 1e-10)
            
            return saliency.numpy()
        except Exception as e:
            logger.error(f"Error in saliency map: {str(e)}")
            # Ø¥Ø±Ø¬Ø¹ Ø®Ø±ÙŠØ·Ø© Ø³ÙˆØ¯Ø§Ø¡ ÙÙŠ Ø£Ø³ÙˆØ£ Ø§Ù„Ø­Ø§Ù„Ø§Øª
            return np.zeros((self.img_size[0], self.img_size[1]))
    
    def process_image(self, image_path):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ù…Ù„Ø© Ù„ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            img_array, img_preprocessed = self.load_and_preprocess_image(image_path)
            
            if img_array is None:
                return None
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            preds = self.model.predict(img_preprocessed, verbose=0)[0]
            pred_class_idx = np.argmax(preds)
            confidence = preds[pred_class_idx]
            
            # Ø­Ø³Ø§Ø¨ Grad-CAM
            heatmap = self.make_gradcam_heatmap(img_preprocessed, pred_class_idx)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            original_img = keras.preprocessing.image.load_img(image_path)
            original_array = keras.preprocessing.image.img_to_array(original_img) / 255.0
            
            # ØªÙƒØ¨ÙŠØ± heatmap
            heatmap_resized = cv2.resize(
                heatmap, 
                (original_array.shape[1], original_array.shape[0])
            )
            
            # ØªÙ„ÙˆÙŠÙ† heatmap
            heatmap_colored = cv2.applyColorMap(
                np.uint8(255 * heatmap_resized), 
                cv2.COLORMAP_JET
            )
            heatmap_colored = heatmap_colored / 255.0
            
            # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±
            overlay = original_array * 0.5 + heatmap_colored * 0.5
            
            return {
                'original': original_array,
                'heatmap': heatmap_resized,
                'overlay': overlay,
                'predictions': preds,
                'pred_class_idx': int(pred_class_idx),
                'confidence': float(confidence),
                'class_name': self.class_names[pred_class_idx]
            }
        
        except Exception as e:
            logger.error(f"Error processing image {image_path}: {str(e)}")
            return None
    
    def convert_to_base64(self, img_array):
        """
        ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© numpy Ø¥Ù„Ù‰ base64 Ù„Ù„Ù€ JSON
        """
        try:
            import base64
            from io import BytesIO
            from PIL import Image
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ uint8
            img_uint8 = np.uint8(img_array * 255)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© PIL
            pil_img = Image.fromarray(img_uint8)
            
            # Ø­ÙØ¸ ÙÙŠ BytesIO
            buffer = BytesIO()
            pil_img.save(buffer, format='JPEG', quality=85)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            return f"data:image/jpeg;base64,{img_base64}"
        
        except Exception as e:
            logger.error(f"Error converting to base64: {str(e)}")
            return None
    
    def generate_gradcam_samples(self, image_paths, output_dir):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ± ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            results = []
            
            for idx, img_path in enumerate(image_paths):
                logger.info(f"Processing image {idx + 1}/{len(image_paths)}: {os.path.basename(img_path)}")
                
                result = self.process_image(img_path)
                
                if result is None:
                    logger.warning(f"Failed to process {img_path}")
                    continue
                
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64
                result['original_base64'] = self.convert_to_base64(result['original'])
                result['heatmap_base64'] = self.convert_to_base64(
                    cv2.applyColorMap(np.uint8(255 * result['heatmap']), cv2.COLORMAP_JET) / 255.0
                )
                result['overlay_base64'] = self.convert_to_base64(result['overlay'])
                
                # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (arrays)
                del result['original']
                del result['heatmap']
                del result['overlay']
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                result['all_predictions'] = {
                    self.class_names[i]: float(result['predictions'][i]) 
                    for i in range(len(self.class_names))
                }
                del result['predictions']
                
                results.append(result)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            os.makedirs(output_dir, exist_ok=True)
            
            output_data = {
                'generated_at': datetime.now().isoformat(),
                'num_samples': len(results),
                'samples': results
            }
            
            json_path = os.path.join(output_dir, 'gradcam_data.json')
            with open(json_path, 'w') as f:
                json.dump(output_data, f, indent=2)
            
            logger.info(f"Saved {len(results)} samples to {json_path}")
            
            return output_data
        
        except Exception as e:
            logger.error(f"Error generating Grad-CAM samples: {str(e)}")
            return None